{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy Introduction\n",
    "Let's first start spacy. In the first part we are exploring the spacy functions for Natural Language Processing. Particularly, we require to understand the attributes that we can extract out-of-box. We will also explore some functions that are essential for training custom Named-Entity-Recognition model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load english vocabulary\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nlp_details(doc):\n",
    "    for token in doc:\n",
    "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ner_details(doc):\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barrack barrack PROPN NNP compound Xxxxx True False\n",
      "Obama obama PROPN NNP nsubj Xxxxx True False\n",
      "was be VERB VBD ROOT xxx True True\n",
      "the the DET DT det xxx True True\n",
      "President president PROPN NNP attr Xxxxx True False\n",
      "of of ADP IN prep xx True True\n",
      "United united PROPN NNP compound Xxxxx True False\n",
      "States states PROPN NNP pobj Xxxxx True False\n",
      "of of ADP IN prep xx True True\n",
      "America america PROPN NNP pobj Xxxxx True False\n",
      ". . PUNCT . punct . False False\n",
      "Barrack Obama 0 13 PERSON\n",
      "United States of America 35 59 GPE\n"
     ]
    }
   ],
   "source": [
    "# check a small sentence\n",
    "# understand their NLP tags\n",
    "# understand their NER tags\n",
    "\n",
    "doc = nlp(u'Barrack Obama was the President of United States of America.')\n",
    "print_nlp_details(doc)\n",
    "print_ner_details(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57852"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# English vocabulary\n",
    "len(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can declare our own label and use it for custom mapping of the Named Entity Recoginition. For example, we create a label called `USPREZ`. We can use the in-built function of Spacy Matcher, Phrase Matcher to find the words in the vocabulary that match to the new word. However, first we need to add the label to out matcher. The phrase matcher returns phrase that match to the labels. We create a utility function `offsetter` that returns string index of the phrases. This is required to train our custom NER model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare a cutom label - USPREZ for US president\n",
    "# add it to matcher created on top of intial english vocabulary\n",
    "label = \"USPREZ\"\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "for i in [\"Barack\", \"Obama\", \"Barack Obama\"]:\n",
    "    matcher.add(label, None, nlp(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding the label to matcher, let's apply to one sentence. We look at the output that gives us the index of phrases in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2934372180660327885, 0, 1), (2934372180660327885, 0, 2), (2934372180660327885, 1, 2)]\n"
     ]
    }
   ],
   "source": [
    "# test the output of matcher on a custom sentence\n",
    "one = nlp('Barack Obama was the President of United States of America.')\n",
    "matches = matcher(one)\n",
    "print([match for match in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility function to get start and end indices of phrases that match in the doc.\n",
    "\"\"\"\n",
    "def offsetter(label, doc, matchitem):\n",
    "    o_one = len(str(doc[:matchitem[1]]))\n",
    "    subdoc = doc[matchitem[1]:matchitem[2]]\n",
    "    o_two = o_one + len(str(subdoc))\n",
    "    return o_one, o_two, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it for the Barack Obama string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 6, 'USPREZ'), (0, 12, 'USPREZ'), (6, 11, 'USPREZ')]\n"
     ]
    }
   ],
   "source": [
    "# test utility function on custom matcher\n",
    "print([offsetter(label, one, match) for match in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy applied to pandas dataframe\n",
    "One way to fetch data from Wikipedia is to get the daily dumps provide by WikiMedia. But that is too large and parsing it for specific data according to our data may be a tedious task. however, let's see if we can parse similar data using one of the smaller datasets for wikibooks from https://dumps.wikimedia.org/backup-index.html. Let's create a script to parse data from enwikibooks dump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data has already been extracted from xml dump using wikiextractor to these files on my local machine.\n",
    "# sample data is as show below\n",
    "# there is a doc block containing the content\n",
    "\"\"\"\n",
    "<doc id=\"5\" url=\"https://en.wikibooks.org/wiki?curid=5\" title=\"Organic Chemistry/Cover\">\n",
    "Organic Chemistry/Cover\n",
    "\n",
    "Welcome to the world's foremost open content<br>Organic Chemistry Textbook<br>on the web!\n",
    "\n",
    "Organic chemistry is primarily devoted to the unique properties of the carbon atom and its compounds. These compounds play a critical role in biology and ecology, Earth sciences and\n",
    " geology, physics, industry, medicine and — of course — chemistry. At first glance, the new material that organic chemistry brings to the table may seem complicated and daunting, bu\n",
    "t all it takes is concentration and perseverance. Millions of students before you have successfully passed this course and you can too!\n",
    "\n",
    "This field of chemistry is based less on formulas and more on reactions between various molecules under different conditions. Whereas a typical general chemistry question may ask a\n",
    "student to compute an answer with an equation from the chapter that they memorized, a more typical organic chemistry question is along the lines of \"what product will form when subs\n",
    "tance X is treated with solution Y and bombarded by light\". The key to learning organic chemistry is to \"understand\" it rather than cram it in the night before a test. It is all wel\n",
    "l and good to memorize the mechanism of Michael addition, but a superior accomplishment would be the ability to explain \"why\" such a reaction would take place.\n",
    "\n",
    "As in all things, it is easier to build up a body of new knowledge on a foundation of solid prior knowledge. Students will be well served by much of the knowledge brought to this su\n",
    "bject from the subject of General Chemistry. Concepts with particular importance to organic chemists are covalent bonding, Molecular Orbit theory, VSEPR Modeling, understanding acid\n",
    "/base chemistry vis-a-vis pKa values, and even trends of the periodic table. This is by no means a comprehensive list of the knowledge you should have gained already in order to ful\n",
    "ly understand the subject of organic chemistry, but it should give you some idea of the things you need to know to succeed in an organic chemistry test or course.\n",
    "\n",
    "Organic Chemistry is one of the subjects which are very useful and close to our daily life. We always try to figure out some of the unknown mysteries of our daily life through our f\n",
    "actious thinking habit, which generates superstitions. Through the help of chemistry we can help ourselves to get out of this kind of superstition.\n",
    "We always try to find the ultimate truth through our own convenience. In the ancient past we had struggled to make things to go as per our need. In that context we have found fire,\n",
    "house, food, transportation, etc…\n",
    "\n",
    "Now the burning question is: \"how can chemistry help our daily life?\" To find the answer of this questions, we have to know the subject thoroughly. Let us start it from now.\n",
    "\n",
    "\n",
    "</doc>\n",
    "\"\"\"\n",
    "fname = \"/Users/saurabh/workspace/datasets/wiki/AA/wiki_00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, WordPunctTokenizer\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtkz = WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We assign each document with a unique page id.\n",
    "We assign every line in the document with unique id.\n",
    "\"\"\"\n",
    "def process_file(fname):\n",
    "    with open(fname) as f:\n",
    "        lines = f.readlines()\n",
    "    data = {}\n",
    "    curr = False\n",
    "    curr_data = []\n",
    "    for line in lines:\n",
    "        if line.startswith('</doc'):\n",
    "            if len(curr_data) >= 1:\n",
    "                data[doc_id] = curr_data\n",
    "            curr = False\n",
    "        if curr:\n",
    "            if len(line) > 20:\n",
    "                curr_data.append((doc_id, uuid.uuid4(), line.strip()))\n",
    "        if line.startswith('<doc'):\n",
    "            doc_id = line.split('<doc id=\"')[1].split('\"')[0]\n",
    "            curr = True\n",
    "    return curr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('5', UUID('9d53b591-7309-418d-ac36-bde4b11c7902'), 'Organic Chemistry/Cover')\n"
     ]
    }
   ],
   "source": [
    "data = process_file(fname)\n",
    "print(data[0])\n",
    "raw_df = pd.DataFrame(data, columns=[\"ids\", \"txt_id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>txt_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>9d53b591-7309-418d-ac36-bde4b11c7902</td>\n",
       "      <td>Organic Chemistry/Cover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>51b182e3-b3e9-4454-8a55-3808b54a1c1b</td>\n",
       "      <td>Welcome to the world's foremost open content&lt;b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>031c71b5-4db7-4e77-84ef-1b3dff096b49</td>\n",
       "      <td>Organic chemistry is primarily devoted to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2e31e4ca-f43c-4d63-9fd1-6e14e7b55e64</td>\n",
       "      <td>This field of chemistry is based less on formu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6ab99378-e42d-47bc-a25b-12909b1d0d0b</td>\n",
       "      <td>As in all things, it is easier to build up a b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ids                                txt_id  \\\n",
       "0   5  9d53b591-7309-418d-ac36-bde4b11c7902   \n",
       "1   5  51b182e3-b3e9-4454-8a55-3808b54a1c1b   \n",
       "2   5  031c71b5-4db7-4e77-84ef-1b3dff096b49   \n",
       "3   5  2e31e4ca-f43c-4d63-9fd1-6e14e7b55e64   \n",
       "4   5  6ab99378-e42d-47bc-a25b-12909b1d0d0b   \n",
       "\n",
       "                                                text  \n",
       "0                            Organic Chemistry/Cover  \n",
       "1  Welcome to the world's foremost open content<b...  \n",
       "2  Organic chemistry is primarily devoted to the ...  \n",
       "3  This field of chemistry is based less on formu...  \n",
       "4  As in all things, it is easier to build up a b...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4542\n"
     ]
    }
   ],
   "source": [
    "print(raw_df[\"ids\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply spacy.nlp to all the documents. After this we will extract Name Entities dfrom the \n",
    "raw_df[\"nlp_txt\"] = raw_df[\"text\"].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>txt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>nlp_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>9d53b591-7309-418d-ac36-bde4b11c7902</td>\n",
       "      <td>Organic Chemistry/Cover</td>\n",
       "      <td>(Organic, Chemistry, /, Cover)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>51b182e3-b3e9-4454-8a55-3808b54a1c1b</td>\n",
       "      <td>Welcome to the world's foremost open content&lt;b...</td>\n",
       "      <td>(Welcome, to, the, world, 's, foremost, open, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>031c71b5-4db7-4e77-84ef-1b3dff096b49</td>\n",
       "      <td>Organic chemistry is primarily devoted to the ...</td>\n",
       "      <td>(Organic, chemistry, is, primarily, devoted, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2e31e4ca-f43c-4d63-9fd1-6e14e7b55e64</td>\n",
       "      <td>This field of chemistry is based less on formu...</td>\n",
       "      <td>(This, field, of, chemistry, is, based, less, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6ab99378-e42d-47bc-a25b-12909b1d0d0b</td>\n",
       "      <td>As in all things, it is easier to build up a b...</td>\n",
       "      <td>(As, in, all, things, ,, it, is, easier, to, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ids                                txt_id  \\\n",
       "0   5  9d53b591-7309-418d-ac36-bde4b11c7902   \n",
       "1   5  51b182e3-b3e9-4454-8a55-3808b54a1c1b   \n",
       "2   5  031c71b5-4db7-4e77-84ef-1b3dff096b49   \n",
       "3   5  2e31e4ca-f43c-4d63-9fd1-6e14e7b55e64   \n",
       "4   5  6ab99378-e42d-47bc-a25b-12909b1d0d0b   \n",
       "\n",
       "                                                text  \\\n",
       "0                            Organic Chemistry/Cover   \n",
       "1  Welcome to the world's foremost open content<b...   \n",
       "2  Organic chemistry is primarily devoted to the ...   \n",
       "3  This field of chemistry is based less on formu...   \n",
       "4  As in all things, it is easier to build up a b...   \n",
       "\n",
       "                                             nlp_txt  \n",
       "0                     (Organic, Chemistry, /, Cover)  \n",
       "1  (Welcome, to, the, world, 's, foremost, open, ...  \n",
       "2  (Organic, chemistry, is, primarily, devoted, t...  \n",
       "3  (This, field, of, chemistry, is, based, less, ...  \n",
       "4  (As, in, all, things, ,, it, is, easier, to, b...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get named entities\n",
    "def get_ners(doc):\n",
    "    val = []\n",
    "    for ent in doc.ents:\n",
    "#         return ent.text, ent.start_char, ent.end_char, ent.label_\n",
    "        val.append((ent.text, ent.label_))\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = raw_df[\"nlp_txt\"].apply(get_ners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('General Chemistry', 'ORG'),\n",
       " ('Concepts', 'PERSON'),\n",
       " ('Molecular Orbit', 'PRODUCT'),\n",
       " ('Modeling', 'GPE')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.loc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Organic chemistry is primarily devoted to the unique properties of the carbon atom and its compounds. These compounds play a critical role in biology and ecology, Earth sciences and geology, physics, industry, medicine and — of course — chemistry. At first glance, the new material that organic chemistry brings to the table may seem complicated and daunting, but all it takes is concentration and perseverance. Millions of students before you have successfully passed this course and you can too!'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.loc[2, [\"text\"]][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Seed Words\n",
    "Fetch the seed words from wikipedia page of list of musical instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Agung a Tamlang', 'Bamboo slit drum', 'Enlarge', 'Balafon', 'Cajón']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "list_mi_url = \"https://en.wikipedia.org/wiki/List_of_musical_instruments\"\n",
    "resp = requests.get(list_mi_url).text\n",
    "\n",
    "soup = BeautifulSoup(resp, 'lxml')\n",
    "\n",
    "def get_links(lnks):\n",
    "    mis = []\n",
    "    for lnk in lnks:\n",
    "        title = lnk.get('title')\n",
    "        if title != None:\n",
    "            mis.append(title)\n",
    "    return mis\n",
    "\n",
    "tbls = soup.findAll('table',{'class':'wikitable sortable'})\n",
    "\n",
    "mi_seeds = []\n",
    "for tbl in tbls:\n",
    "    lnks = tbl.findAll('a')\n",
    "    mi_seeds.extend(get_links(lnks))\n",
    "\n",
    "print(len(mi_seeds))\n",
    "mi_seeds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Music Instrument Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run NERs on these dumps from wikipedia. However, let's try capturing our own custom data. We will now try to train NER. But before that we require annotated data. We will create data basis the following algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is a starter for Named Entity Recognition for Wikipedia data.\n",
    "We have to do the following tasks in sequence:\n",
    "1. Extract data from Wikipedia<br />\n",
    "2. Annotate the data corresponding to an algorithm. Current algorithm employed<br />\n",
    "    2.1 Start with seed_words. call `wikipedia.page(seed_word)`<br />\n",
    "    2.2 For every page, take the title and the first line. Since, seed are musical words, if title is present in first line of the page. We mark it as MUSIC token.<br />\n",
    "    2.3 Navigate to the first 5 links, most probably they are also music words. So, fetch first link, and again do 2.2.<br />\n",
    "    2.4 Go to specified depth.<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_words = [\"musical instruments\"]\n",
    "seed_words = set(mi_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bass Drum',\n",
       " 'Goblet drum',\n",
       " 'Hira-daiko (page does not exist)',\n",
       " 'Idakka',\n",
       " 'Ilimba drum',\n",
       " 'Janggu',\n",
       " \"Jew's harp\",\n",
       " 'Kakko (instrument)',\n",
       " 'Kanjira',\n",
       " 'Kendang']"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_seeds[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page_data(wiki_page, indent=0):\n",
    "    data_map = {}\n",
    "    print('\\t'*indent ,wiki_page.title)\n",
    "#     print('\\t' ,wiki_page.content.split('.')[0])\n",
    "#     print('\\t' ,wiki_page.links[:4])\n",
    "    data_map[\"title\"] = wiki_page.title\n",
    "    data_map[\"line1\"] = wiki_page.content.split('.')[0]\n",
    "    return data_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_music_data(seed, data, depth=-1):\n",
    "    if depth == 1:\n",
    "        return\n",
    "    search_pages = wikipedia.search(seed)\n",
    "    for sp in search_pages:\n",
    "        wiki_page = wikipedia.page(sp)\n",
    "        data.append(fetch_page_data(wiki_page))\n",
    "        for wpl in wiki_page.links[:1]:\n",
    "            lwpage = wikipedia.page(wpl)\n",
    "            data.append(fetch_page_data(lwpage, 1))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wiki_page_data(wiki_page, num_links=5, indent=0, print_title=True):\n",
    "    if print_title:\n",
    "        print('\\t'*indent ,wiki_page.title)\n",
    "    title = wiki_page.title\n",
    "    line1 = wiki_page.content.split('.')[0]\n",
    "    other_content = wiki_page.content\n",
    "    linked_titles = wiki_page.links[:num_links]\n",
    "    return title, line1, other_content, linked_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_music_related_titles(seed, data, depth=-1, fetch_associations=False):\n",
    "    if depth == 1:\n",
    "        return\n",
    "    search_pages = wikipedia.search(seed)\n",
    "    for sp in search_pages:\n",
    "        try:\n",
    "            wiki_page = wikipedia.page(sp)\n",
    "            title, line1, other_content, linked_titles = fetch_wiki_page_data(wiki_page)\n",
    "            music_corpus.append((title, line1, other_content, linked_titles))\n",
    "            # fetch pages of associated links on the website\n",
    "            if fetch_associations:\n",
    "                for wpl in linked_titles:\n",
    "                    try:\n",
    "                        lwpage = wikipedia.page(wpl)\n",
    "                        music_corpus.append(fetch_wiki_page_data(lwpage, indent=1))\n",
    "                    except:\n",
    "                        print(wpl, \"No match\")\n",
    "        except:\n",
    "            print(sp, \"No match\")\n",
    "    return music_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wiki_page(title, print_title=False):\n",
    "    wiki_page = wikipedia.page(title)\n",
    "    return fetch_wiki_page_data(wiki_page, print_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_corpus = []\n",
    "for idx, seed in seed_words:\n",
    "    print(idx)\n",
    "    try:\n",
    "        music_corpus.append(get_wiki_page(seed, print_title=False))\n",
    "    except:\n",
    "        print(seed, \"**** No match or ambiguous ****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>line1</th>\n",
       "      <th>content</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agung a tamlang</td>\n",
       "      <td>The Agung a Tamlang is a type of Philippine sl...</td>\n",
       "      <td>The Agung a Tamlang is a type of Philippine sl...</td>\n",
       "      <td>[Acme siren, Agung, Babendil, Bass drum, Bell ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Slit drum</td>\n",
       "      <td>A slit drum is a hollow percussion instrument</td>\n",
       "      <td>A slit drum is a hollow percussion instrument....</td>\n",
       "      <td>['Aparima, 'ote'a, 'upa'upa, Aboriginal dugout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Balafon</td>\n",
       "      <td>The balafon is a kind of xylophone or percussi...</td>\n",
       "      <td>The balafon is a kind of xylophone or percussi...</td>\n",
       "      <td>[Acme siren, African Rumba, Afro Celt Sound Sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cajón</td>\n",
       "      <td>A cajón (Spanish: [kaˈxon]; \"box\", \"crate\" or ...</td>\n",
       "      <td>A cajón (Spanish: [kaˈxon]; \"box\", \"crate\" or ...</td>\n",
       "      <td>[Acme siren, Acoustic guitar, Afro-Peruvian mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Castanets</td>\n",
       "      <td>Castanets, also known as clackers or palillos,...</td>\n",
       "      <td>Castanets, also known as clackers or palillos,...</td>\n",
       "      <td>[Acme siren, African dance, Ahenk, Ajoblanco, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title                                              line1  \\\n",
       "0  Agung a tamlang  The Agung a Tamlang is a type of Philippine sl...   \n",
       "1        Slit drum      A slit drum is a hollow percussion instrument   \n",
       "2          Balafon  The balafon is a kind of xylophone or percussi...   \n",
       "3            Cajón  A cajón (Spanish: [kaˈxon]; \"box\", \"crate\" or ...   \n",
       "4        Castanets  Castanets, also known as clackers or palillos,...   \n",
       "\n",
       "                                             content  \\\n",
       "0  The Agung a Tamlang is a type of Philippine sl...   \n",
       "1  A slit drum is a hollow percussion instrument....   \n",
       "2  The balafon is a kind of xylophone or percussi...   \n",
       "3  A cajón (Spanish: [kaˈxon]; \"box\", \"crate\" or ...   \n",
       "4  Castanets, also known as clackers or palillos,...   \n",
       "\n",
       "                                               links  \n",
       "0  [Acme siren, Agung, Babendil, Bass drum, Bell ...  \n",
       "1  ['Aparima, 'ote'a, 'upa'upa, Aboriginal dugout...  \n",
       "2  [Acme siren, African Rumba, Afro Celt Sound Sy...  \n",
       "3  [Acme siren, Acoustic guitar, Afro-Peruvian mu...  \n",
       "4  [Acme siren, African dance, Ahenk, Ajoblanco, ...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df = pd.DataFrame(music_corpus, columns=[\"title\", \"line1\", \"content\", \"links\"])\n",
    "music_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the crawled data in a csv file\n",
    "# f_name = \"/Users/saurabh/workspace/datasets/wikimusic/instruments.csv\"\n",
    "# music_df.to_csv(f_name, index=None, header=True, sep='|', na_rep='-')\n",
    "\n",
    "# save title and first line of wikipage\n",
    "f_name = \"/Users/saurabh/workspace/datasets/wikimusic/instruments_line1.csv\"\n",
    "music_df.loc[:, [\"title\", \"line1\"]].to_csv(f_name, index=None, header=True, sep='|', na_rep='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy on Music Instruments data corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>line1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agung a tamlang</td>\n",
       "      <td>The Agung a Tamlang is a type of Philippine sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Slit drum</td>\n",
       "      <td>A slit drum is a hollow percussion instrument</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title                                              line1\n",
       "0  Agung a tamlang  The Agung a Tamlang is a type of Philippine sl...\n",
       "1        Slit drum      A slit drum is a hollow percussion instrument"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load instruments_line.csv\n",
    "mi_f_name = \"/Users/saurabh/workspace/datasets/wikimusic/instruments_line1.csv\"\n",
    "mi_df = pd.read_csv(mi_f_name, delimiter='|')\n",
    "mi_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_brackets = r'\\([^)]*\\)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_combinations(title):\n",
    "    title = title.lower()\n",
    "    title = re.sub(in_brackets, '', title).strip()\n",
    "    nn_grams = [title]\n",
    "    t_split = title.split(r'\\s+')\n",
    "    # hack to handle ngrams generated that start with stopwords\n",
    "    if any(word in stopset for word in t_split):\n",
    "        return nn_grams\n",
    "    for i in range(2, len(title)-1):\n",
    "        the_grams = ngrams(t_split, i)\n",
    "        str_grams = [\" \".join(words) for words in the_grams]\n",
    "        nn_grams.extend(str_grams)\n",
    "    return list(set(nn_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "triange triange ADJ JJ ROOT xxxx True False\n",
      "( ( PUNCT -LRB- punct ( False False\n",
      "musical musical ADJ JJ amod xxxx True False\n",
      "instrument instrument NOUN NN appos xxxx True False\n",
      ") ) PUNCT -RRB- punct ) False False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['triange']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"triange (musical instrument)\"\n",
    "doc = nlp(t)\n",
    "print_ner_details(doc)\n",
    "print(\"\")\n",
    "print_nlp_details(doc)\n",
    "title_combinations(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_raw_vocab = mi_df[\"title\"].apply(title_combinations)\n",
    "mi_raw_vocab[-10:]\n",
    "mi_vocab = flatten(mi_raw_vocab.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "604\n",
      "['agung a tamlang', 'slit drum', 'balafon', 'cajón', 'castanets']\n",
      "59096\n"
     ]
    }
   ],
   "source": [
    "print(len(mi_vocab))\n",
    "print(mi_vocab[:5])\n",
    "\n",
    "nlp_vocab = nlp.vocab\n",
    "print(len(nlp_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"MUSIC\"\n",
    "matcher = PhraseMatcher(nlp_vocab)\n",
    "for mi_word in mi_vocab:\n",
    "    matcher.add(label, None, nlp(mi_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9502756511836460881, 1, 2), (9502756511836460881, 5, 6)]\n",
      "[(3, 9, 'MUSIC'), (16, 20, 'MUSIC')]\n",
      "[' ashiko', ' drum']\n"
     ]
    }
   ],
   "source": [
    "test_string = \"The ashiko  is a drum, shaped like a tapered cylinder (or truncated cone) with the head on the wide end, and the narrow end open\"\n",
    "one = nlp(test_string.lower())\n",
    "matches = matcher(one)\n",
    "print([match for match in matches])\n",
    "offsets = [offsetter(label, one, match) for match in matches]\n",
    "print(offsets)\n",
    "print([test_string[offset[0]:offset[1]+1] for offset in offsets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_data(text, ret_data):\n",
    "    tkns = wtkz.tokenize(text)\n",
    "    for tkn in tkns:\n",
    "        ret_data.append((tkn, 'O'))\n",
    "    return ret_data\n",
    "\n",
    "def split_and_mark(row):\n",
    "    ret_data = []\n",
    "    line1, title = row\n",
    "    lline1 = line1.lower()\n",
    "    ltitle = title.lower()\n",
    "    idx = line1.lower().find(title.lower())\n",
    "    if idx == -1:\n",
    "        ret_data = append_to_data(line1, ret_data)\n",
    "    else:\n",
    "        end_idx = idx+len(title)\n",
    "        sd = line1[:idx]\n",
    "        ret_data = append_to_data(sd, ret_data)\n",
    "        ret_data.append((line1[idx:end_idx], 'MUSIC'))\n",
    "        sd = line1[end_idx:]\n",
    "        ret_data = append_to_data(sd, ret_data)\n",
    "    return ret_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(A, O), (musical instrument, MUSIC), (is, O),...\n",
       "1    [(During, O), (the, O), (20th, O), (century, O...\n",
       "2    [(21st-century classical music, MUSIC), (is, O...\n",
       "3    [(The, O), (terms, O), (A-side and B-side, MUS...\n",
       "4    [(This, O), (is, O), (a, O), (list of musical ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marked_data = music_df.apply(split_and_mark, axis=1)\n",
    "marked_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data = ''\n",
    "for dlist in marked_data:\n",
    "    for dtup in dlist:\n",
    "        write_data += dtup[0] + '\\t' + dtup[1] + '\\n'\n",
    "    write_data += '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.txt\", \"w\") as f:\n",
    "    f.write(write_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data from output.txt\n",
    "\"\"\"\n",
    "The     O\n",
    "ANS synthesizer MUSIC\n",
    "is      O\n",
    "a       O\n",
    "photoelectronic O\n",
    "musical O\n",
    "instrument      O\n",
    "created O\n",
    "by      O\n",
    "Russian O\n",
    "engineer        O\n",
    "Evgeny  O\n",
    "Murzin  O\n",
    "from    O\n",
    "1937    O\n",
    "to      O\n",
    "1957    O\n",
    "\n",
    "ARP Instruments MUSIC\n",
    ",       O\n",
    "Inc     O\n",
    "\n",
    "The     O\n",
    "ARP Odyssey     MUSIC\n",
    "is      O\n",
    "an      O\n",
    "analog  O\n",
    "synthesizer     O\n",
    "introduced      O\n",
    "in      O\n",
    "1972    O\n",
    "\"\"\"\n",
    "\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
