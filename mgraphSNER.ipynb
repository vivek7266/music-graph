{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK and StanforNLP\n",
    "\n",
    "Nltk has built in class for Named Entity Recognition for Stanford NER Tagger. For this purpose first we need to download Stanford Named Entity recognizer from https://nlp.stanford.edu/software/CRF-NER.shtml. We will demo using english language NER and then go on to built our own custom Music Instruments Recognizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nltk corpus stopwords. if not present, download it.\n",
    "try:\n",
    "    from nltk.corpus import stopwords\n",
    "    stopset = set(stopwords.words('english'))\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "    stopset = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ner tagger based on stanford ner tagger\n",
    "jar = './stanford-ner-tagger/stanford-ner.jar'\n",
    "model = './stanford-ner-tagger/english.all.3class.distsim.crf.ser.gz'\n",
    "ner_tagger = StanfordNERTagger(model, jar, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Barack', 'PERSON'), ('Obama', 'PERSON'), ('stands', 'O'), ('at', 'O'), ('the', 'O'), ('Oval', 'LOCATION'), (',', 'O'), ('addressing', 'O'), ('the', 'O'), ('nation', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# Test a sentence\n",
    "sentence = \"Barack Obama stands at the Oval, addressing the nation.\"\n",
    "words = nltk.word_tokenize(sentence)\n",
    "print(ner_tagger.tag(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Music Instruments NER\n",
    "Load the music data as scraped from Wikipedia page of list of Instruments. Use that to create custom NER tagged (\"MUSIC\") data. We use this data to train Stanford NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '/Users/saurabh/workspace/datasets/wikimusic/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    604\n",
       "line1    604\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load instruments_line.csv\n",
    "mi_f_name = parent_dir + \"instruments_line1.csv\"\n",
    "mi_df = pd.read_csv(mi_f_name, delimiter='|')\n",
    "mi_df.head(2)\n",
    "mi_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "# split the data into train and test set\n",
    "msk = np.random.rand(len(tagged_data)) < 0.8\n",
    "train = mi_df[msk]\n",
    "test = mi_df[~msk]\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex to match any title such as 'Clave (rhythm)' to remove the bracket and the words inside.\n",
    "in_brackets = r'\\([^)]*\\)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda function to to get a flattened list from list of lists.\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create combinations of title, such as, 'agung a tamlang' should also encompass its synonyms or 'agung' and 'tamlang'. This method is still under creation.\n",
    "def title_combinations(title):\n",
    "    title = title.lower()\n",
    "    title = re.sub(in_brackets, '', title).strip()\n",
    "    nn_grams = [title]\n",
    "    t_split = title.split(r'\\s+')\n",
    "    # hack to handle ngrams generated that start with stopwords\n",
    "    if any(word in stopset for word in t_split):\n",
    "        return nn_grams\n",
    "    for i in range(2, len(title)-1):\n",
    "        the_grams = ngrams(t_split, i)\n",
    "        str_grams = [\" \".join(words) for words in the_grams]\n",
    "        nn_grams.extend(str_grams)\n",
    "    return list(set(nn_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aung a lung']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test title combinations\n",
    "t = \"aung a lung (musical instrument)\"\n",
    "title_combinations(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtkz = WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_data(text, ret_data, tag=None, use_ner=False):\n",
    "    tkns = wtkz.tokenize(text)\n",
    "    if tag is None:\n",
    "        if use_ner:\n",
    "            ret_data.extend(ner_tagger.tag(tkns))\n",
    "        else:\n",
    "            for tkn in tkns:\n",
    "                ret_data.append((tkn, 'O'))\n",
    "    else:\n",
    "        for tkn in tkns:\n",
    "            ret_data.append((tkn, tag))\n",
    "    return ret_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'O'), ('slit', 'O'), ('drum', 'O'), ('is', 'O'), ('a', 'O'), ('hollow', 'O'), ('percussion', 'O'), ('instrument', 'O')]\n",
      "[('aung', 'MUSIC'), ('a', 'MUSIC'), ('lung', 'MUSIC')]\n"
     ]
    }
   ],
   "source": [
    "print(append_to_data(\"A slit drum is a hollow percussion instrument\", []))\n",
    "print(append_to_data(\"aung a lung\", [], \"MUSIC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_mark(row, use_ner=False):\n",
    "    ret_data = []\n",
    "    title, line1 = row\n",
    "    lline1 = line1.lower()\n",
    "    ltitle = title.lower()\n",
    "    ltitle_combs = title_combinations(title)\n",
    "    idx = line1.lower().find(title.lower())\n",
    "    if idx == -1:\n",
    "        ret_data = append_to_data(line1, ret_data)\n",
    "    else:\n",
    "        end_idx = idx+len(title)\n",
    "        sd = line1[:idx]\n",
    "        ret_data = append_to_data(sd, ret_data, use_ner=use_ner)\n",
    "        match = line1[idx:end_idx]\n",
    "        ret_data = append_to_data(match, ret_data, tag=\"MUSIC\")\n",
    "        sd = line1[end_idx:]\n",
    "        ret_data = append_to_data(sd, ret_data, use_ner=use_ner)\n",
    "    return ret_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'O'),\n",
       " ('slit', 'MUSIC'),\n",
       " ('drum', 'MUSIC'),\n",
       " ('is', 'O'),\n",
       " ('a', 'O'),\n",
       " ('hollow', 'O'),\n",
       " ('percussion', 'O'),\n",
       " ('instrument', 'O')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_and_mark((\"slit drum\", \"A slit drum is a hollow percussion instrument\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_data = train.apply(split_and_mark, axis=1)\n",
    "tagged_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_sents = mi_df.loc[:, \"line1\"].values.tolist()\n",
    "# tkzd_sents = [wtkz.tokenize(sent) for sent in all_sents]\n",
    "# tagged_sents = ner_tagger.tag_sents(tkzd_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data = ''\n",
    "for dlist in train:\n",
    "    for dtup in dlist:\n",
    "        write_data += dtup[0] + '\\t' + dtup[1] + '\\n'\n",
    "    write_data += '\\n'\n",
    "\n",
    "with open(\"./stanford-ner-tagger/train/mi_tagged_split.txt\", \"w\") as f:\n",
    "    f.write(write_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd stanford-ner-tagger/\n",
    "# !java -cp \"stanford-ner.jar:lib/*\" -mx4g edu.stanford.nlp.ie.crf.CRFClassifier -prop train/prop.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load custom ner model\n",
    "m_jar = './stanford-ner-tagger/stanford-ner.jar'\n",
    "m_model = './stanford-ner-tagger/dummy-ner-model-music.ser.gz'\n",
    "m_ner_tagger = StanfordNERTagger(m_model, m_jar, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Shiva', 'MUSIC'), (\"'\", 'MUSIC'), ('s', 'O'), ('damru', 'O'), ('is', 'O'), ('an', 'O'), ('instrument', 'O'), ('that', 'O'), ('is', 'O'), ('hollow', 'O'), ('located', 'O'), ('at', 'O'), ('New', 'O'), ('York', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# test custom NER model.\n",
    "sentence = \"Shiva's damru is an instrument that is hollow located at New York.\"\n",
    "words = wtkz.tokenize(sentence)\n",
    "print(m_ner_tagger.tag(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom NER tagged test data\n",
    "all_sents = test.loc[:, \"line1\"].values.tolist()\n",
    "tkzd_sents = [wtkz.tokenize(sent) for sent in all_sents]\n",
    "tagged_sents = m_ner_tagger.tag_sents(tkzd_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('A', 'O'),\n",
       "  ('wood', 'MUSIC'),\n",
       "  ('block', 'MUSIC'),\n",
       "  ('(', 'O'),\n",
       "  ('also', 'O'),\n",
       "  ('spelled', 'O'),\n",
       "  ('as', 'O'),\n",
       "  ('a', 'O'),\n",
       "  ('single', 'O'),\n",
       "  ('word', 'O'),\n",
       "  (',', 'O'),\n",
       "  ('woodblock', 'O'),\n",
       "  (')', 'O'),\n",
       "  ('is', 'O'),\n",
       "  ('a', 'O'),\n",
       "  ('small', 'O'),\n",
       "  ('slit', 'O'),\n",
       "  ('drum', 'O'),\n",
       "  ('made', 'O'),\n",
       "  ('from', 'O'),\n",
       "  ('a', 'O'),\n",
       "  ('single', 'O'),\n",
       "  ('piece', 'O'),\n",
       "  ('of', 'O'),\n",
       "  ('wood', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('used', 'O'),\n",
       "  ('as', 'O'),\n",
       "  ('a', 'O'),\n",
       "  ('percussion', 'O'),\n",
       "  ('instrument', 'O')]]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sents[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth values of test data\n",
    "test_truth = test.apply(split_and_mark, axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "0.4336283185840708\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy of custom NER Tagger\n",
    "count = 0\n",
    "for i in range(len(test)):\n",
    "    tags = tagged_sents[i]\n",
    "    true_tags = test_truth[i]\n",
    "    accurate = True\n",
    "    for tag, true_tag in zip(tags, true_tags):\n",
    "        if tag[1] == \"MUSIC\" and true_tags[1] != \"MUSIC\":\n",
    "            accurate = False\n",
    "    if accurate:\n",
    "        count += 1\n",
    "print(count)\n",
    "print(count/len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
